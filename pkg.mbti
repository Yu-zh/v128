package "Yu-zh/v128"

type V128

fn f32x4_abs(V128) -> V128
fn f32x4_add(V128, V128) -> V128
fn f32x4_ceil(V128) -> V128
fn f32x4_const_(Float, Float, Float, Float) -> V128
fn f32x4_convert_i32x4_s(V128) -> V128
fn f32x4_convert_i32x4_u(V128) -> V128
fn f32x4_demote_f64x2_zero(V128) -> V128
fn f32x4_div(V128, V128) -> V128
fn f32x4_eq(V128, V128) -> V128
fn f32x4_extract_lane(V128, Int) -> Float
fn f32x4_floor(V128) -> V128
fn f32x4_ge(V128, V128) -> V128
fn f32x4_gt(V128, V128) -> V128
fn f32x4_le(V128, V128) -> V128
fn f32x4_lt(V128, V128) -> V128
fn f32x4_max(V128, V128) -> V128
fn f32x4_min(V128, V128) -> V128
fn f32x4_mul(V128, V128) -> V128
fn f32x4_ne(V128, V128) -> V128
fn f32x4_nearest(V128) -> V128
fn f32x4_neg(V128) -> V128
fn f32x4_pmax(V128, V128) -> V128
fn f32x4_pmin(V128, V128) -> V128
fn f32x4_relaxed_max(V128, V128) -> V128
fn f32x4_relaxed_min(V128, V128) -> V128
fn f32x4_replace_lane(V128, Int, Float) -> V128
fn f32x4_splat(Float) -> V128
fn f32x4_sqrt(V128) -> V128
fn f32x4_sub(V128, V128) -> V128
fn f32x4_trunc(V128) -> V128

fn f64x2_abs(V128) -> V128
fn f64x2_add(V128, V128) -> V128
fn f64x2_ceil(V128) -> V128
fn f64x2_const_(Double, Double) -> V128
fn f64x2_convert_low_i32x4_s(V128) -> V128
fn f64x2_convert_low_i32x4_u(V128) -> V128
fn f64x2_div(V128, V128) -> V128
fn f64x2_eq(V128, V128) -> V128
fn f64x2_extract_lane(V128, Int) -> Double
fn f64x2_floor(V128) -> V128
fn f64x2_ge(V128, V128) -> V128
fn f64x2_gt(V128, V128) -> V128
fn f64x2_le(V128, V128) -> V128
fn f64x2_lt(V128, V128) -> V128
fn f64x2_max(V128, V128) -> V128
fn f64x2_min(V128, V128) -> V128
fn f64x2_mul(V128, V128) -> V128
fn f64x2_ne(V128, V128) -> V128
fn f64x2_nearest(V128) -> V128
fn f64x2_neg(V128) -> V128
fn f64x2_pmax(V128, V128) -> V128
fn f64x2_pmin(V128, V128) -> V128
fn f64x2_promote_low_f32x4(V128) -> V128
fn f64x2_relaxed_max(V128, V128) -> V128
fn f64x2_relaxed_min(V128, V128) -> V128
fn f64x2_replace_lane(V128, Int, Double) -> V128
fn f64x2_splat(Double) -> V128
fn f64x2_sqrt(V128) -> V128
fn f64x2_sub(V128, V128) -> V128
fn f64x2_trunc(V128) -> V128

fn i16x8_abs(V128) -> V128
fn i16x8_add(V128, V128) -> V128
fn i16x8_add_sat_s(V128, V128) -> V128
fn i16x8_add_sat_u(V128, V128) -> V128
fn i16x8_all_true(V128) -> Bool
fn i16x8_avgr_u(V128, V128) -> V128
fn i16x8_bitmask(V128) -> Int
fn i16x8_const_(UInt16, UInt16, UInt16, UInt16, UInt16, UInt16, UInt16, UInt16) -> V128
fn i16x8_eq(V128, V128) -> V128
fn i16x8_extadd_pairwise_i8x16_s(V128) -> V128
fn i16x8_extadd_pairwise_i8x16_u(V128) -> V128
fn i16x8_extend_high_i8x16_s(V128) -> V128
fn i16x8_extend_high_i8x16_u(V128) -> V128
fn i16x8_extend_low_i8x16_s(V128) -> V128
fn i16x8_extend_low_i8x16_u(V128) -> V128
fn i16x8_extmul_high_i8x16_s(V128, V128) -> V128
fn i16x8_extmul_high_i8x16_u(V128, V128) -> V128
fn i16x8_extmul_low_i8x16_s(V128, V128) -> V128
fn i16x8_extmul_low_i8x16_u(V128, V128) -> V128
fn i16x8_extract_lane_s(V128, Int) -> UInt
fn i16x8_extract_lane_u(V128, Int) -> UInt
fn i16x8_ge_s(V128, V128) -> V128
fn i16x8_ge_u(V128, V128) -> V128
fn i16x8_gt_s(V128, V128) -> V128
fn i16x8_gt_u(V128, V128) -> V128
fn i16x8_le_s(V128, V128) -> V128
fn i16x8_le_u(V128, V128) -> V128
fn i16x8_lt_s(V128, V128) -> V128
fn i16x8_lt_u(V128, V128) -> V128
fn i16x8_max_s(V128, V128) -> V128
fn i16x8_max_u(V128, V128) -> V128
fn i16x8_min_s(V128, V128) -> V128
fn i16x8_min_u(V128, V128) -> V128
fn i16x8_mul(V128, V128) -> V128
fn i16x8_narrow_i32x4_s(V128, V128) -> V128
fn i16x8_narrow_i32x4_u(V128, V128) -> V128
fn i16x8_ne(V128, V128) -> V128
fn i16x8_neg(V128) -> V128
fn i16x8_relaxed_dot_s_i8x16(V128, V128) -> V128
fn i16x8_replace_lane(V128, Int, UInt) -> V128
fn i16x8_shl(V128, Int) -> V128
fn i16x8_shr_s(V128, Int) -> V128
fn i16x8_shr_u(V128, Int) -> V128
fn i16x8_splat(UInt16) -> V128
fn i16x8_sub(V128, V128) -> V128
fn i16x8_sub_sat_s(V128, V128) -> V128
fn i16x8_sub_sat_u(V128, V128) -> V128

fn i32x4_abs(V128) -> V128
fn i32x4_add(V128, V128) -> V128
fn i32x4_all_true(V128) -> Bool
fn i32x4_bitmask(V128) -> Int
fn i32x4_const_(UInt, UInt, UInt, UInt) -> V128
fn i32x4_eq(V128, V128) -> V128
fn i32x4_extadd_pairwise_i16x8_s(V128) -> V128
fn i32x4_extadd_pairwise_i16x8_u(V128) -> V128
fn i32x4_extend_high_i16x8_s(V128) -> V128
fn i32x4_extend_high_i16x8_u(V128) -> V128
fn i32x4_extend_low_i16x8_s(V128) -> V128
fn i32x4_extend_low_i16x8_u(V128) -> V128
fn i32x4_extmul_high_i16x8_s(V128, V128) -> V128
fn i32x4_extmul_high_i16x8_u(V128, V128) -> V128
fn i32x4_extmul_low_i16x8_s(V128, V128) -> V128
fn i32x4_extmul_low_i16x8_u(V128, V128) -> V128
fn i32x4_extract_lane(V128, Int) -> UInt
fn i32x4_ge_s(V128, V128) -> V128
fn i32x4_ge_u(V128, V128) -> V128
fn i32x4_gt_s(V128, V128) -> V128
fn i32x4_gt_u(V128, V128) -> V128
fn i32x4_le_s(V128, V128) -> V128
fn i32x4_le_u(V128, V128) -> V128
fn i32x4_lt_s(V128, V128) -> V128
fn i32x4_lt_u(V128, V128) -> V128
fn i32x4_max_s(V128, V128) -> V128
fn i32x4_max_u(V128, V128) -> V128
fn i32x4_min_s(V128, V128) -> V128
fn i32x4_min_u(V128, V128) -> V128
fn i32x4_mul(V128, V128) -> V128
fn i32x4_ne(V128, V128) -> V128
fn i32x4_neg(V128) -> V128
fn i32x4_relaxed_dot_add_s_i16x8(V128, V128) -> V128
fn i32x4_relaxed_trunc_f32x4_s(V128) -> V128
fn i32x4_relaxed_trunc_f32x4_u(V128) -> V128
fn i32x4_relaxed_trunc_f64x2_s_zero(V128) -> V128
fn i32x4_relaxed_trunc_f64x2_u_zero(V128) -> V128
fn i32x4_replace_lane(V128, Int, UInt) -> V128
fn i32x4_shl(V128, Int) -> V128
fn i32x4_shr_s(V128, Int) -> V128
fn i32x4_shr_u(V128, Int) -> V128
fn i32x4_splat(UInt) -> V128
fn i32x4_sub(V128, V128) -> V128
fn i32x4_trunc_sat_f32x4_s(V128) -> V128
fn i32x4_trunc_sat_f32x4_u(V128) -> V128
fn i32x4_trunc_sat_f64x2_s_zero(V128) -> V128
fn i32x4_trunc_sat_f64x2_u_zero(V128) -> V128

fn i64x2_abs(V128) -> V128
fn i64x2_add(V128, V128) -> V128
fn i64x2_all_true(V128) -> Bool
fn i64x2_bitmask(V128) -> Int
fn i64x2_const_(UInt64, UInt64) -> V128
fn i64x2_eq(V128, V128) -> V128
fn i64x2_extend_high_i32x4_s(V128) -> V128
fn i64x2_extend_high_i32x4_u(V128) -> V128
fn i64x2_extend_low_i32x4_s(V128) -> V128
fn i64x2_extend_low_i32x4_u(V128) -> V128
fn i64x2_extmul_high_i32x4_s(V128, V128) -> V128
fn i64x2_extmul_high_i32x4_u(V128, V128) -> V128
fn i64x2_extmul_low_i32x4_s(V128, V128) -> V128
fn i64x2_extmul_low_i32x4_u(V128, V128) -> V128
fn i64x2_extract_lane(V128, Int) -> UInt64
fn i64x2_ge_s(V128, V128) -> V128
fn i64x2_gt_s(V128, V128) -> V128
fn i64x2_le_s(V128, V128) -> V128
fn i64x2_lt_s(V128, V128) -> V128
fn i64x2_mul(V128, V128) -> V128
fn i64x2_ne(V128, V128) -> V128
fn i64x2_neg(V128) -> V128
fn i64x2_replace_lane(V128, Int, UInt64) -> V128
fn i64x2_shl(V128, Int) -> V128
fn i64x2_shr_s(V128, Int) -> V128
fn i64x2_shr_u(V128, Int) -> V128
fn i64x2_splat(UInt64) -> V128
fn i64x2_sub(V128, V128) -> V128

fn i8x16_abs(V128) -> V128
fn i8x16_add(V128, V128) -> V128
fn i8x16_add_sat_s(V128, V128) -> V128
fn i8x16_add_sat_u(V128, V128) -> V128
fn i8x16_all_true(V128) -> Bool
fn i8x16_avgr_u(V128, V128) -> V128
fn i8x16_bitmask(V128) -> Int
fn i8x16_const_(Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte, Byte) -> V128
fn i8x16_eq(V128, V128) -> V128
fn i8x16_extract_lane_s(V128, Int) -> UInt
fn i8x16_extract_lane_u(V128, Int) -> UInt
fn i8x16_ge_s(V128, V128) -> V128
fn i8x16_ge_u(V128, V128) -> V128
fn i8x16_gt_s(V128, V128) -> V128
fn i8x16_gt_u(V128, V128) -> V128
fn i8x16_le_s(V128, V128) -> V128
fn i8x16_le_u(V128, V128) -> V128
fn i8x16_lt_s(V128, V128) -> V128
fn i8x16_lt_u(V128, V128) -> V128
fn i8x16_max_s(V128, V128) -> V128
fn i8x16_max_u(V128, V128) -> V128
fn i8x16_min_s(V128, V128) -> V128
fn i8x16_min_u(V128, V128) -> V128
fn i8x16_narrow_i16x8_s(V128, V128) -> V128
fn i8x16_narrow_i16x8_u(V128, V128) -> V128
fn i8x16_ne(V128, V128) -> V128
fn i8x16_neg(V128) -> V128
fn i8x16_popcnt(V128) -> V128
fn i8x16_relaxed_swizzle(V128, V128) -> V128
fn i8x16_replace_lane(V128, Int, UInt) -> V128
fn i8x16_shl(V128, Int) -> V128
fn i8x16_shr_s(V128, Int) -> V128
fn i8x16_shr_u(V128, Int) -> V128
fn i8x16_shuffle(V128, V128, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int, Int) -> V128
fn i8x16_splat(Byte) -> V128
fn i8x16_sub(V128, V128) -> V128
fn i8x16_sub_sat_s(V128, V128) -> V128
fn i8x16_sub_sat_u(V128, V128) -> V128
fn i8x16_swizzle(V128, V128) -> V128

fn v128_and_(V128, V128) -> V128
fn v128_andnot(V128, V128) -> V128
fn v128_any_true(V128) -> Bool
fn v128_bitselect(V128, V128, V128) -> V128

fn v128_load(FixedArray[Byte], Int) -> V128
fn v128_load16_lane(FixedArray[Byte], Int, V128, Int) -> V128
fn v128_load16_splat(FixedArray[Byte], Int) -> V128
fn v128_load16x4_s(FixedArray[Byte], Int) -> V128
fn v128_load16x4_u(FixedArray[Byte], Int) -> V128
fn v128_load32_lane(FixedArray[Byte], Int, V128, Int) -> V128
fn v128_load32_splat(FixedArray[Byte], Int) -> V128
fn v128_load32_zero(FixedArray[Byte], Int) -> V128
fn v128_load32x2_s(FixedArray[Byte], Int) -> V128
fn v128_load32x2_u(FixedArray[Byte], Int) -> V128
fn v128_load64_lane(FixedArray[Byte], Int, V128, Int) -> V128
fn v128_load64_splat(FixedArray[Byte], Int) -> V128
fn v128_load64_zero(FixedArray[Byte], Int) -> V128
fn v128_load8_lane(FixedArray[Byte], Int, V128, Int) -> V128
fn v128_load8_splat(FixedArray[Byte], Int) -> V128
fn v128_load8x8_s(FixedArray[Byte], Int) -> V128
fn v128_load8x8_u(FixedArray[Byte], Int) -> V128
fn v128_not(V128) -> V128
fn v128_or_(V128, V128) -> V128
fn v128_store(FixedArray[Byte], Int, V128) -> Unit
fn v128_store16_lane(FixedArray[Byte], Int, V128, Int) -> Unit
fn v128_store32_lane(FixedArray[Byte], Int, V128, Int) -> Unit
fn v128_store64_lane(FixedArray[Byte], Int, V128, Int) -> Unit
fn v128_store8_lane(FixedArray[Byte], Int, V128, Int) -> Unit
fn v128_xor(V128, V128) -> V128

fn v128_to_string(V128) -> String
fn v128_eq(V128, V128) -> Bool
